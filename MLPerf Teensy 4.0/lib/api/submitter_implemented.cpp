/*
 * Copyright 2024 The MLPerf Authors. All Rights Reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 * ==============================================================================
 *
 * This file is generated by Gemini based on user inputs.
 * Implements the MLPerf Tiny API for a Teensy 4.0 using TFLM.
 */

// 1. API-Header
#include "submitter_implemented.h"
#include "internally_implemented.h" // Für ee_get_buffer()

// 2. Arduino & C Standard-Bibliotheken
#include <Arduino.h>  // Für Serial, micros()
#include <stdarg.h>   // Für va_list, va_start, va_end
#include <stdio.h>    // Für vsnprintf
#include <string.h>   // Für libc-Hooks (memcpy, etc.)

// 3. TFLM-Header
#include "tensorflow/lite/micro/micro_log.h"
#include "tensorflow/lite/micro/micro_interpreter.h"
#include "tensorflow/lite/micro/micro_mutable_op_resolver.h"
#include "tensorflow/lite/schema/schema_generated.h"

// ===================================================================
// DEINE MODELL-KONFIGURATION (Übernommen aus deinem Snippet)
// ===================================================================

#if TH_MODEL_VERSION == EE_MODEL_VERSION_IC01
  #include "ic01_model_data.h" // Enthält das ResNet-Modell
  const unsigned char* g_model = pretrainedResnet_quant_tflite;
  constexpr int kTensorArenaSize = 150 * 1024; // 100 KB

#elif TH_MODEL_VERSION == EE_MODEL_VERSION_KWS01
  #include "kws01_model_data.h" // Enthält das DS-CNN-Modell
  const unsigned char* g_model = kws_ref_model_tflite;
  constexpr int kTensorArenaSize = 20 * 1024; // 20 KB

#elif TH_MODEL_VERSION == EE_MODEL_VERSION_VWW01
  #include "vww01_model_data.h" // Enthält das MobileNetV1-Modell
  const unsigned char* g_model = vww_96_int8_tflite;
  constexpr int kTensorArenaSize = 335 * 1024; // 335 KB

#elif TH_MODEL_VERSION == EE_MODEL_VERSION_AD01
  #include "ad01_model_data.h" // Enthält das Autoencoder-Modell
  const unsigned char* g_model = ad01_int8_tflite;
  constexpr int kTensorArenaSize = 50 * 1024; // 50 KB

#elif TH_MODEL_VERSION == EE_MODEL_VERSION_STRWW01
  #include "strww01_model_data.h" // Enthält das TinyML RNN-Modell
  const unsigned char* g_model = str_ww_ref_model_tflite;
  constexpr int kTensorArenaSize = 30 * 1024; // 30 KB

#else
  #error "TH_MODEL_VERSION wurde nicht auf ein gültiges Modell gesetzt!"
#endif

// ===================================================================
// GLOBALE VARIABLEN FÜR TFLM
// ===================================================================


namespace { // Anonymer Namespace, um globale Variablen "privat" zu halten
const tflite::Model* model = nullptr;
tflite::MicroInterpreter* interpreter = nullptr;
TfLiteTensor* model_input = nullptr;
TfLiteTensor* model_output = nullptr;
tflite::MicroOpResolver* op_resolver = nullptr;

// Die Tensor Arena!
// Wird vom Linker in das RAM des Teensy gelegt.
// `alignas(16)` ist eine TFLM-Anforderung für beste Performance.
alignas(16) static uint8_t tensor_arena[kTensorArenaSize];
} // namespace

/**
 * @brief Implementiert die DebugLog-Funktion, die TFLM erwartet.
 *
 * TFLM (insbesondere der MicroErrorReporter) ruft diese C-Funktion
 * auf, um Log-Meldungen auszugeben. Wir leiten sie an die
 * serielle Schnittstelle des Teensy weiter.
 */
extern "C" void DebugLog(const char* s) {
  Serial.print(s);
}

/**
 * @brief Fügt die TFLM-Operatoren hinzu, die für das
 * aktuell ausgewählte Modell benötigt werden.
 *
 * Jedes Modell erhält einen minimalen, maßgeschneiderten Resolver,
 * um den Flash-Speicherverbrauch zu optimieren.
 */
void AddOpsToResolver() {
  #if TH_MODEL_VERSION == EE_MODEL_VERSION_IC01 // IC (ResNet)
    // Dieses ResNet-Modell [cite: 152] benötigt Faltungs-, Additions- (für die
    // Residual-Blöcke) und Pooling-Operationen.
    static tflite::MicroMutableOpResolver<5> micro_op_resolver;
    micro_op_resolver.AddConv2D();
    micro_op_resolver.AddAdd(); // Wichtig für Residual-Verbindungen
    micro_op_resolver.AddAveragePool2D();
    micro_op_resolver.AddReshape();
    micro_op_resolver.AddSoftmax();
    op_resolver = &micro_op_resolver; // Weist den lokalen Resolver dem globalen Zeiger zu

  #elif TH_MODEL_VERSION == EE_MODEL_VERSION_KWS01 // KWS (DS-CNN)
    // Dieses Modell ist ein "Depthwise Separable" CNN.
    static tflite::MicroMutableOpResolver<5> micro_op_resolver;
    micro_op_resolver.AddDepthwiseConv2D(); // Speziell für DS-CNN
    micro_op_resolver.AddConv2D();
    micro_op_resolver.AddAveragePool2D();
    micro_op_resolver.AddReshape();
    micro_op_resolver.AddSoftmax();
    op_resolver = &micro_op_resolver;

  #elif TH_MODEL_VERSION == EE_MODEL_VERSION_VWW01 // VWW (MobileNetV1)
    // MobileNetV1 ist ebenfalls ein "Depthwise Separable" CNN.
    static tflite::MicroMutableOpResolver<6> micro_op_resolver;
    micro_op_resolver.AddConv2D();
    micro_op_resolver.AddDepthwiseConv2D();
    micro_op_resolver.AddAveragePool2D();
    micro_op_resolver.AddReshape();
    micro_op_resolver.AddSoftmax();
    micro_op_resolver.AddMean(); // Oft für das finale Pooling verwendet
    op_resolver = &micro_op_resolver;

  #elif TH_MODEL_VERSION == EE_MODEL_VERSION_AD01 // AD (Autoencoder)
    // Dieses Modell ist ein reiner "Fully Connected" (FC) Autoencoder
    // [cite: 229] [cite_start]und verwendet ReLU als Aktivierung[cite: 230].
    static tflite::MicroMutableOpResolver<2> micro_op_resolver;
    micro_op_resolver.AddFullyConnected();
    micro_op_resolver.AddRelu();
    op_resolver = &micro_op_resolver;
    // HINWEIS: Die Berechnung des Anomaly-Scores (MSE) [cite: 232] wird
    // typischerweise auf dem Host durchgeführt. Das On-Chip-Modell
    // benötigt daher keine Ops wie Sub, Square oder Mean.

  #elif TH_MODEL_VERSION == EE_MODEL_VERSION_STRWW01 // STRWW (RNN)
    // Dies ist ein Recurrent Neural Network (RNN).
    static tflite::MicroMutableOpResolver<4> micro_op_resolver;
    micro_op_resolver.AddUnidirectionalSequenceLSTM(); // Long Short-Term Memory
    micro_op_resolver.AddFullyConnected();
    micro_op_resolver.AddSoftmax();
    micro_op_resolver.AddReshape();
    op_resolver = &micro_op_resolver;

  #else
    #error "TH_MODEL_VERSION nicht erkannt in AddOpsToResolver()"
  #endif
}

// ===================================================================
// 6 WICHTIGSTE API-FUNKTIONEN
// ===================================================================

/**
 * @brief Lädt die Eingabedaten vom Host (via ee_get_buffer)
 * in den Input-Tensor des Modells.
 */
void th_load_tensor() {
  size_t input_size = model_input->bytes;
  
  // ee_get_buffer() holt die Daten, die der Host zuvor mit dem "db load"
  // Befehl gesendet hat.
  size_t host_buffer_size = ee_get_buffer(model_input->data.uint8, input_size);

  if (host_buffer_size != input_size) {
    th_printf("FEHLER: Host-Puffer (%d bytes) passt nicht zur Tensor-Größe (%d bytes)!\r\n",
              host_buffer_size, input_size);
  }
}

/**
 * @brief Gibt die Ergebnisse der Inferenz an den Host zurück.
 *
 * HINWEIS: Diese Implementierung sendet den rohen Output-Tensor als Hex-String.
 * Für eine vollständige Genauigkeitsmessung (z.B. AUC bei AD01)
 * wäre hier zusätzliche Logik (Post-Processing) erforderlich.
 */
void th_results() {
  // Sende den Header für die Ergebnisse
  th_printf("m-results-");

  // Sende die Anzahl der Bytes im Output-Tensor
  size_t output_size = model_output->bytes;
  th_printf("num-%d-", output_size);

  // Sende den Inhalt des Tensors als Hex-String
  // (uint8_t wird angenommen, da wir quantisierte Modelle verwenden)
  th_printf("in-");
  for (size_t i = 0; i < output_size; i++) {
    th_printf("%02x", model_output->data.uint8[i]);
  }
  th_printf("-\r\n");
}

/**
 * @brief Führt eine einzelne Inferenz mit TFLM aus.
 */
void th_infer() {
  if (interpreter->Invoke() != kTfLiteOk) {
    MicroPrintf("FEHLER: interpreter->Invoke() ist fehlgeschlagen!");
  }
}

/**
 * @brief Sendet einen Zeitstempel an den Host.
 * Verwendet micros() für hohe Auflösung.
 */
void th_timestamp(void) {
  // Das Framework erwartet die Zeit in Mikrosekunden (us)
  // EE_MSG_TIMESTAMP ist in internally_implemented.h als "m-lap-us-%lu\r\n" definiert
  th_printf(EE_MSG_TIMESTAMP, micros());
}

/**
 * @brief Eine Implementierung von printf(), die die serielle Schnittstelle
 * des Teensy (Serial.print) verwendet.
 */
void th_printf(const char *fmt, ...) {
  char buffer[128]; // Ein Puffer für die formatierte Zeichenkette
  va_list args;
  va_start(args, fmt);
  // vsnprintf ist die "sichere" Version von sprintf
  vsnprintf(buffer, sizeof(buffer), fmt, args);
  va_end(args);

  Serial.print(buffer);
}

/**
 * @brief Eine Implementierung von getchar(), die auf ein Zeichen
 * von der seriellen Schnittstelle wartet (blockierend).
 */
char th_getchar() {
  // Warte, bis ein Zeichen verfügbar ist
  while (!Serial.available()) {
    yield();
  }
  return Serial.read();
}

// ===================================================================
// OPTIONALE API-FUNKTIONEN (Für Initialisierung benötigt)
// ===================================================================

/**
 * @brief Initialisiert die serielle Schnittstelle.
 */
void th_serialport_initialize(void) {
}

/**
 * @brief Initialisiert den Timer. (Nicht nötig für Teensy/micros())
 */
void th_timestamp_initialize(void) {
  // Auf Arduino/Teensy ist keine separate Initialisierung
  // für micros() oder millis() erforderlich.
}

/**
 * @brief Wird einmal beim Start aufgerufen, um TFLM zu initialisieren.
 */
void th_final_initialize(void) {

  // 2. Modell laden (g_model wird durch den #if-Block oben gesetzt)
  model = tflite::GetModel(g_model);
  if (model->version() != TFLITE_SCHEMA_VERSION) {
    MicroPrintf("FEHLER: Modell-Schema-Version stimmt nicht überein!");
    return;
  }

  // 3. Operatoren zum Resolver hinzufügen (je nach Modell)
  AddOpsToResolver();

  // 4. Interpreter initialisieren
  static tflite::MicroInterpreter static_interpreter(
      model, *op_resolver, tensor_arena, kTensorArenaSize);
  interpreter = &static_interpreter;

  // 5. Tensoren im Arena-Speicher zuweisen
  if (interpreter->AllocateTensors() != kTfLiteOk) {
    MicroPrintf("FEHLER: AllocateTensors() fehlgeschlagen.");
    return;
  }

  // 6. Zeiger auf Input- und Output-Tensoren holen
  model_input = interpreter->input(0);
  model_output = interpreter->output(0);
}

// Leere Implementierungen für die restlichen optionalen Funktionen
void th_pre() {}
void th_post() {}
void th_command_ready(char volatile *msg) {}


// ===================================================================
// LIBC HOOKS (Erforderlich für das Framework)
// ===================================================================
// Diese Funktionen leiten die Anfragen des Frameworks an die
// Standard-C-Bibliotheken weiter, die mit Arduino/Teensy geliefert werden.

int th_strncmp(const char *str1, const char *str2, size_t n) {
  return strncmp(str1, str2, n);
}

char *th_strncpy(char *dest, const char *src, size_t n) {
  return strncpy(dest, src, n);
}

size_t th_strnlen(const char *str, size_t maxlen) {
  return strnlen(str, maxlen);
}

char *th_strcat(char *dest, const char *src) {
  return strcat(dest, src);
}

char *th_strtok(char *str1, const char *sep) {
  return strtok(str1, sep);
}

int th_atoi(const char *str) {
  return atoi(str);
}

void *th_memset(void *b, int c, size_t len) {
  return memset(b, c, len);
}

void *th_memcpy(void *dst, const void *src, size_t n) {
  return memcpy(dst, src, n);
}

int th_vprintf(const char *format, va_list ap) {
  // Wir leiten dies an unsere th_printf-Implementierung weiter
  char buffer[128];
  vsnprintf(buffer, sizeof(buffer), format, ap);
  Serial.print(buffer);
  // vsnprintf gibt die Anzahl der geschriebenen Zeichen zurück
  return strlen(buffer);
}