/*
 * Copyright 2024 The MLPerf Authors. All Rights Reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 * ==============================================================================
 *
 * This file is generated by Gemini based on user inputs.
 * Implements the MLPerf Tiny API for a Teensy 4.0 using TFLM.
 */

// 1. API-Header
#include "submitter_implemented.h"
#include "internally_implemented.h" // Für ee_get_buffer()

// 2. Arduino & C Standard-Bibliotheken
#include <Arduino.h>  // Für Serial, micros()
#include <stdarg.h>   // Für va_list, va_start, va_end
#include <stdio.h>    // Für vsnprintf
#include <string.h>   // Für libc-Hooks (memcpy, etc.)

// 3. TFLM-Header
#include "tensorflow/lite/micro/micro_error_reporter.h"
#include "tensorflow/lite/micro/micro_interpreter.h"
#include "tensorflow/lite/micro/micro_mutable_op_resolver.h"
#include "tensorflow/lite/schema/schema_generated.h"

// ===================================================================
// DEINE MODELL-KONFIGURATION (Übernommen aus deinem Snippet)
// ===================================================================

#if TH_MODEL_VERSION == EE_MODEL_VERSION_IC01
  #include "ic01_model_data.h" // Enthält das ResNet-Modell
  const unsigned char* g_model = pretrainedResnet_quant_tflite;
  constexpr size_t kTensorArenaSize = 150 * 1024; // 100 KB

#elif TH_MODEL_VERSION == EE_MODEL_VERSION_KWS01
  #include "kws01_model_data.h" // Enthält das DS-CNN-Modell
  const unsigned char* g_model = kws_ref_model_tflite;
  constexpr size_t kTensorArenaSize = 100 * 1024; // 20 KB

#elif TH_MODEL_VERSION == EE_MODEL_VERSION_VWW01
  #include "vww01_model_data.h" // Enthält das MobileNetV1-Modell
  const unsigned char* g_model = vww_96_int8_tflite;
  constexpr size_t kTensorArenaSize = 335 * 1024; // 335 KB

#elif TH_MODEL_VERSION == EE_MODEL_VERSION_AD01
  #include "ad01_model_data.h" // Enthält das Autoencoder-Modell
  const unsigned char* g_model = ad01_int8_tflite;
  constexpr size_t kTensorArenaSize = 50 * 1024; // 50 KB

#elif TH_MODEL_VERSION == EE_MODEL_VERSION_STRWW01
  #include "strww01_model_data.h" // Enthält das TinyML RNN-Modell
  const unsigned char* g_model = str_ww_ref_model_tflite;
  constexpr size_t kTensorArenaSize = 30 * 1024; // 30 KB

#else
  #error "TH_MODEL_VERSION wurde nicht auf ein gültiges Modell gesetzt!"
#endif

// ===================================================================
// GLOBALE VARIABLEN FÜR TFLM
// ===================================================================


namespace { // Anonymer Namespace, um globale Variablen "privat" zu halten
const tflite::Model* model = nullptr;
tflite::MicroInterpreter* interpreter = nullptr;
TfLiteTensor* model_input = nullptr;
TfLiteTensor* model_output = nullptr;
tflite::MicroOpResolver* op_resolver = nullptr;

tflite::MicroErrorReporter micro_error_reporter;
tflite::ErrorReporter* error_reporter = &micro_error_reporter;

// Die Tensor Arena!
// Wird vom Linker in das RAM des Teensy gelegt.
// `alignas(16)` ist eine TFLM-Anforderung für beste Performance.
alignas(16) static uint8_t tensor_arena[kTensorArenaSize];
} // namespace

/**
 * @brief Implementiert die DebugLog-Funktion, die TFLM erwartet.
 *
 * TFLM (insbesondere der MicroErrorReporter) ruft diese C-Funktion
 * auf, um Log-Meldungen auszugeben. Wir leiten sie an die
 * serielle Schnittstelle des Teensy weiter.
 */
extern "C" void DebugLog(const char* s) {
  Serial.print(s);
}

/**
 * @brief Fügt die TFLM-Operatoren hinzu, die für das
 * aktuell ausgewählte Modell benötigt werden.
 *
 * Jedes Modell erhält einen minimalen, maßgeschneiderten Resolver,
 * um den Flash-Speicherverbrauch zu optimieren.
 */
void AddOpsToResolver() {
  #if TH_MODEL_VERSION == EE_MODEL_VERSION_IC01 // IC (ResNet)
    // Dieses ResNet-Modell [cite: 152] benötigt Faltungs-, Additions- (für die
    // Residual-Blöcke) und Pooling-Operationen.
    static tflite::MicroMutableOpResolver<6> micro_op_resolver;
    micro_op_resolver.AddFullyConnected();
    micro_op_resolver.AddConv2D();
    micro_op_resolver.AddAdd(); // Wichtig für Residual-Verbindungen
    micro_op_resolver.AddAveragePool2D();
    micro_op_resolver.AddReshape();
    micro_op_resolver.AddSoftmax();
    op_resolver = &micro_op_resolver; // Weist den lokalen Resolver dem globalen Zeiger zu

  #elif TH_MODEL_VERSION == EE_MODEL_VERSION_KWS01 // KWS (DS-CNN)
    // Dieses Modell ist ein "Depthwise Separable" CNN.
    static tflite::MicroMutableOpResolver<6> micro_op_resolver;
    micro_op_resolver.AddDepthwiseConv2D(); // Speziell für DS-CNN
    micro_op_resolver.AddConv2D();
    micro_op_resolver.AddAveragePool2D();
    micro_op_resolver.AddReshape();
    micro_op_resolver.AddFullyConnected();
    micro_op_resolver.AddSoftmax();
    op_resolver = &micro_op_resolver;

  #elif TH_MODEL_VERSION == EE_MODEL_VERSION_VWW01 // VWW (MobileNetV1)
    // MobileNetV1 ist ebenfalls ein "Depthwise Separable" CNN.
    static tflite::MicroMutableOpResolver<6> micro_op_resolver;
    micro_op_resolver.AddConv2D();
    micro_op_resolver.AddDepthwiseConv2D();
    micro_op_resolver.AddAveragePool2D();
    micro_op_resolver.AddReshape();
    micro_op_resolver.AddSoftmax();
    micro_op_resolver.AddMean(); // Oft für das finale Pooling verwendet
    op_resolver = &micro_op_resolver;

  #elif TH_MODEL_VERSION == EE_MODEL_VERSION_AD01 // AD (Autoencoder)
    // Dieses Modell ist ein reiner "Fully Connected" (FC) Autoencoder
    // [cite: 229] [cite_start]und verwendet ReLU als Aktivierung[cite: 230].
    static tflite::MicroMutableOpResolver<2> micro_op_resolver;
    micro_op_resolver.AddFullyConnected();
    micro_op_resolver.AddRelu();
    op_resolver = &micro_op_resolver;
    // HINWEIS: Die Berechnung des Anomaly-Scores (MSE) [cite: 232] wird
    // typischerweise auf dem Host durchgeführt. Das On-Chip-Modell
    // benötigt daher keine Ops wie Sub, Square oder Mean.

  #elif TH_MODEL_VERSION == EE_MODEL_VERSION_STRWW01 // STRWW (RNN)
    // Dies ist ein Recurrent Neural Network (RNN).
    static tflite::MicroMutableOpResolver<4> micro_op_resolver;
    micro_op_resolver.AddUnidirectionalSequenceLSTM(); // Long Short-Term Memory
    micro_op_resolver.AddFullyConnected();
    micro_op_resolver.AddSoftmax();
    micro_op_resolver.AddReshape();
    op_resolver = &micro_op_resolver;

  #else
    #error "TH_MODEL_VERSION nicht erkannt in AddOpsToResolver()"
  #endif
}

// ===================================================================
// 6 WICHTIGSTE API-FUNKTIONEN
// ===================================================================

void th_load_tensor() {
  size_t input_size_bytes = model_input->bytes;
  static uint8_t temp_host_buffer[MAX_DB_INPUT_SIZE];
  
  size_t host_buffer_size = ee_get_buffer(temp_host_buffer, input_size_bytes);

  if (host_buffer_size != input_size_bytes) {
    th_printf("FEHLER: Host-Puffer (%d) passt nicht zur Tensor-Groesse (%d)!\r\n", 
              (int)host_buffer_size, (int)input_size_bytes);
  }
  
  if (model_input->type == kTfLiteInt8) {
    int8_t* tensor_data = model_input->data.int8;
    for (size_t i = 0; i < input_size_bytes; i++) {
      // KORREKTUR: Gleiche Transformation wie Python (Wert - 128)
      int16_t temp = (int16_t)temp_host_buffer[i] - 128;
      // Clamping (sollte nicht nötig sein, aber sicher ist sicher)
      if (temp > 127) temp = 127;
      if (temp < -128) temp = -128;
      tensor_data[i] = (int8_t)temp;
    }
  } 
  else if (model_input->type == kTfLiteUInt8) {
    uint8_t* tensor_data = model_input->data.uint8;
    memcpy(tensor_data, temp_host_buffer, input_size_bytes);
  }
  else {
    th_printf("FEHLER: Unbekannter Input-Tensor-Typ!");
  }
}
/**
 * @brief Gibt die Ergebnisse der Inferenz an den Host zurück.
 *
 * KORRIGIERTE VERSION: Liest den Output-Tensor als int8_t (signed),
 * da das Modell so konvertiert wurde.
 */
void th_results() {
  // 1. Sende den erforderlichen Header
  th_printf("m-results-[");

  // 2. Hole den Output-Tensor
  TfLiteTensor* output = model_output;

  // 3. Bestimme die Anzahl der Elemente im Output
  size_t output_size = output->dims->data[output->dims->size - 1];

  // 4. Hole die Quantisierungs-Parameter aus dem Tensor
  float scale = output->params.scale;
  int32_t zero_point = output->params.zero_point;

  // 5. HIER IST DER FIX:
  //    Wir MÜSSEN den Tensor als int8_t (signed) lesen,
  //    nicht als uint8_t (unsigned).
  int8_t* output_data = output->data.int8;

  // 6. Schleife: Dequantisiere jeden Wert und drucke ihn
  for (size_t i = 0; i < output_size; i++) {
    // DEQUANTISIERUNG: (Wert - Nullpunkt) * Skalierungsfaktor
    float float_val = ((float)output_data[i] - (float)zero_point) * scale;
    
    th_printf("%f", float_val);
    
    // Füge ein Komma hinzu, außer beim letzten Wert
    if (i < output_size - 1) {
      th_printf(",");
    }
  }
  
  // 7. Sende den abschließenden Footer
  th_printf("]\r\n");
}

/**
 * @brief Führt eine einzelne Inferenz mit TFLM aus.
 */
void th_infer() {
  if (interpreter->Invoke() != kTfLiteOk) {
    th_printf("FEHLER: interpreter->Invoke() ist fehlgeschlagen!");
  }
}

/**
 * @brief Sendet einen Zeitstempel an den Host.
 * Verwendet micros() für hohe Auflösung.
 */
void th_timestamp(void) {
  // Das Framework erwartet die Zeit in Mikrosekunden (us)
  // EE_MSG_TIMESTAMP ist in internally_implemented.h als "m-lap-us-%lu\r\n" definiert
  th_printf(EE_MSG_TIMESTAMP, micros());
}

/**
 * @brief Eine Implementierung von printf(), die die serielle Schnittstelle
 * des Teensy (Serial.print) verwendet.
 */
void th_printf(const char *fmt, ...) {
  char buffer[128]; // Ein Puffer für die formatierte Zeichenkette
  va_list args;
  va_start(args, fmt);
  // vsnprintf ist die "sichere" Version von sprintf
  vsnprintf(buffer, sizeof(buffer), fmt, args);
  va_end(args);

  Serial.print(buffer);
}

/**
 * @brief Eine Implementierung von getchar(), die auf ein Zeichen
 * von der seriellen Schnittstelle wartet (blockierend).
 */
char th_getchar() {
  // Warte, bis ein Zeichen verfügbar ist
  while (!Serial.available()) {
    yield();
  }
  return Serial.read();
}

// ===================================================================
// OPTIONALE API-FUNKTIONEN (Für Initialisierung benötigt)
// ===================================================================

/**
 * @brief Initialisiert die serielle Schnittstelle.
 */
void th_serialport_initialize(void) {
}

/**
 * @brief Initialisiert den Timer. (Nicht nötig für Teensy/micros())
 */
void th_timestamp_initialize(void) {
  // Auf Arduino/Teensy ist keine separate Initialisierung
  // für micros() oder millis() erforderlich.
}

/**
 * @brief Wird einmal beim Start aufgerufen, um TFLM zu initialisieren.
 */
void th_final_initialize(void) {

  // 2. Modell laden (g_model wird durch den #if-Block oben gesetzt)
  model = tflite::GetModel(g_model);
  /*
  if (model->version() != TFLITE_SCHEMA_VERSION) {
    th_printf("FEHLER: Modell-Schema-Version stimmt nicht überein!");
    return;
  }*/

  // 3. Operatoren zum Resolver hinzufügen (je nach Modell)
  AddOpsToResolver();
 
  // 4. Interpreter initialisieren
  static tflite::MicroInterpreter static_interpreter(
      model, *op_resolver, tensor_arena, kTensorArenaSize, 
      error_reporter, nullptr);
  interpreter = &static_interpreter;

  // 5. Tensoren im Arena-Speicher zuweisen
  if (interpreter->AllocateTensors() != kTfLiteOk) {
    th_printf("FEHLER: AllocateTensors() fehlgeschlagen.");
    return;
  }

  // 6. Zeiger auf Input- und Output-Tensoren holen
  model_input = interpreter->input(0);
  model_output = interpreter->output(0);

  // DEBUG: Zeige Input-Tensor-Infos
  th_printf("DEBUG Input Tensor:\r\n");
  th_printf("  Type: %d (0=float32, 1=int32, 2=uint8, 3=int64, 9=int8)\r\n", model_input->type);
  th_printf("  Bytes: %d\r\n", model_input->bytes);
  th_printf("  Scale: %f\r\n", model_input->params.scale);
  th_printf("  Zero point: %d\r\n", model_input->params.zero_point);
  th_printf("  Dims: ");
  for (int i = 0; i < model_input->dims->size; i++) {
    th_printf("%d ", model_input->dims->data[i]);
  }
  th_printf("\r\n");
  
  // DEBUG: Zeige Output-Tensor-Infos
  th_printf("DEBUG Output Tensor:\r\n");
  th_printf("  Type: %d\r\n", model_output->type);
  th_printf("  Bytes: %d\r\n", model_output->bytes);
  th_printf("  Scale: %f\r\n", model_output->params.scale);
  th_printf("  Zero point: %d\r\n", model_output->params.zero_point);

}

// Leere Implementierungen für die restlichen optionalen Funktionen
void th_pre() {}
void th_post() {}
void th_command_ready(char volatile *msg) {
  ee_serial_command_parser_callback((char*) msg);
}


// ===================================================================
// LIBC HOOKS (Erforderlich für das Framework)
// ===================================================================
// Diese Funktionen leiten die Anfragen des Frameworks an die
// Standard-C-Bibliotheken weiter, die mit Arduino/Teensy geliefert werden.

int th_strncmp(const char *str1, const char *str2, size_t n) {
  return strncmp(str1, str2, n);
}

char *th_strncpy(char *dest, const char *src, size_t n) {
  return strncpy(dest, src, n);
}

size_t th_strnlen(const char *str, size_t maxlen) {
  return strnlen(str, maxlen);
}

char *th_strcat(char *dest, const char *src) {
  return strcat(dest, src);
}

char *th_strtok(char *str1, const char *sep) {
  return strtok(str1, sep);
}

int th_atoi(const char *str) {
  return atoi(str);
}

void *th_memset(void *b, int c, size_t len) {
  return memset(b, c, len);
}

void *th_memcpy(void *dst, const void *src, size_t n) {
  return memcpy(dst, src, n);
}

int th_vprintf(const char *format, va_list ap) {
  // Wir leiten dies an unsere th_printf-Implementierung weiter
  char buffer[128];
  vsnprintf(buffer, sizeof(buffer), format, ap);
  Serial.print(buffer);
  // vsnprintf gibt die Anzahl der geschriebenen Zeichen zurück
  return strlen(buffer);
}